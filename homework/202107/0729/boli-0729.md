Kafak是一个消息队列。 不同的生产者可以将不同的消息可以被放入不同的主题中(topic)。 消费者可以根据需要去订阅自己关心的topic. 在存储层面，同一个topic的数据会被partition后分别存在不同的服务器上。 同时会对分区做副本避免单点故障问题。 副本之间也有Leader和follower之分。 类似于数据库的master slave结构。 生产者发送的数据直接发送到Leader partition, Follower partition会去向leader同步数据。 消费数据也是从leader读取。 
kafak中的消费者都会属于某一个消费者组： 同一个消费者组的多个消费者会竞争消费一条消息，当消息被其中一个消费者处理，那么同一组中的其他消费者便无法再消费这条消息。但是属于不同消费者组的其他消费者依然能够消费该条消息。

kafak是主从式的架构。 主节点为controller, 主节点需要使用zookeeper来管理从节点并保证数据的一致性。 Kafak中的所有Broker在启动时候需要向zookeeper注册， zookeeper保留了所有的节点的信息，便于进行leader election. 选举主要是哪个节点先注册，分配的优先级就高，就可以优先作为leader. 成为leader后，需要不断和zookeeper通信，读取集群整体信息，并将其整理生成集群元数据信息。 这些信息被发送给其他服务器，让从节点感知整体的布局。
当我们创建一个topic的时候，首先会在zookeeper上创建一个对于的目录。 kafka 会把分区方案存储在相应的目录下。 此时主节点监听到这一改变会同步这个目录信息并将其同步给其他节点。 这样集群就都赶着这个分区方案， 各从节点创建好目录创建分区副本。
Kafak利用linux的NIO技术，省区进程切换和数据拷贝， 优化了性能。 具体是在消费者读取数据时候，Kafak 通过将数据从操作系统缓存直接发送至网卡，省去了拷贝数据到kafak应用程序的操作。
从网络设计的角度： 生产者发送的数据会被一个Acceptor接收， Broker里面有默认多线程。 Acceptor将数据封装为socketchannel, 发给具体线程处理。 消费者线程处理socketChannel, 如果是写请求就写入数据到磁盘， 如果是读就返回数据给消费者。