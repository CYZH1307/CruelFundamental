# Why Redis is Fast

- Redis is an in-memory data store so compared to disk-based storage, it reduce the disk IO and access latency.
- Redis has built-in data structure that are optimized for performance and memory usage.
- Redis is single-thread, which minimizes the cost in context switch and cross-thread synchronization.
- Redis use event-loop based IO multiplexing, which allows one single thread to handle multiple IO stream, this maximizes the throughput because in-memory operation is much less expensive than the network IO.

# Blocking IO

- When IO happens, the thread will need to be waiting there until the IO completes. This waiting status is also called blocking. When a thread is blocked, it yields the access to CPU, and CPU schedule will assign the computing resource to another active thread. When the data from IO is ready, the blocked thread will be waken up to do further processing.

# Non-Blocking IO

- When IO happens, instead of being blocked there, the thread will able able to execute the remaining logic immediately. When the thread needs the data and signalling the OS for the result, it will receives an error if the data is not ready, or the result if it's ready. In this case, the thread won't be blocked and it can continue to do the next polling. Only when the data is ready, the processing logic will be applied to the IO result.

# Asynchronous IO

- In the async IO cases, instead of keeping the thread blocking/polling the result from the IO, the kernel will trigger the registered callback when the data is ready.
- Asynchronous IO can be either blocking or non-blocking, if it's blocking, the processing thread will be blocked and waiting for the callback to be triggered.
